% !TEX root = ../../main.tex

\subsection{Análisis y conclusiones}\label{sec:01-sudoku-analisis-y-conclusiones}
La comparación entre solvers mostró que Chuffed resolvió el Sudoku en tiempos menores que Gecode. Chuffed aprovecha propagación y aprendizaje de conflictos para recortar el árbol de búsqueda, lo que a menudo le da ventaja de velocidad, aunque en algunos casos exploró un número de nodos/fallos comparable o incluso mayor. Gecode, en cambio, depende más de la heurística de búsqueda elegida: con heurísticas potentes también pudo resolver eficazmente, pero en general sus tiempos fueron superiores a los de Chuffed.

Entre las estrategias de búsqueda, la heurística \texttt{wdeg\_split} (dom/wdeg con división de dominio) produjo los mejores resultados en nodos y fallos. Esta heurística prioriza las variables que participan en más conflictos y las aborda primero, reduciendo drásticamente el espacio de búsqueda. La estrategia \texttt{ff\_min} (first\_fail con valor mínimo) también ayudó a disminuir los retrocesos al elegir celdas con dominios pequeños, pero su beneficio fue menor que el de \texttt{wdeg\_split}. En contraste, \texttt{inorder\_min} (orden de entrada con valor mínimo) resultó la menos eficiente: exploró muchos más nodos y alcanzó una profundidad similar (hasta completar el tablero) sin predecir bien dónde ocurren los fallos, lo que se tradujo en más retrocesos y tiempos mayores.

Finalmente, se observó que añadir las restricciones redundantes de suma (fila/columna/caja suman 45) no aportó mejoras y, en varios casos, introdujo un ligero sobrecoste. Aunque la literatura sugiere que las redundancias pueden ayudar, en nuestro modelo de Sudoku el propagador de \textit{all\_different} ya realiza una poda muy fuerte, de modo que las sumas apenas añaden información y sí más trabajo de propagación. En nuestras pruebas, las métricas con redundancias fueron en general similares o algo peores (ligeros aumentos de tiempo y nodos), especialmente con estrategias como \texttt{wdeg\_split}. Con heurísticas simples tampoco se observó un beneficio claro. En conjunto, el modelo con sumas no redujo el backtracking ni el tiempo de resolución, por lo que preferimos dejarlas desactivadas por defecto.

